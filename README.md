# Интеллектуальный помощник

Веб-приложение для общения с ИИ через Ollama. Позволяет задавать вопросы и получать ответы от языковой модели в удобном интерфейсе.

## Возможности

- Чат с ИИ в реальном времени
- Настройка параметров модели (температура, длина ответа)
- Поддержка разных моделей (Gemma 3, Llama 3.2, Qwen 2.5)
- Автоматическое сохранение истории разговоров
- Адаптивный дизайн для разных устройств

## Установка и запуск

### 1. Установка Ollama

Скачайте Ollama с официального сайта [ollama.com/download](https://ollama.com/download) и установите для вашей операционной системы.

### 2. Скачивание модели

В командной строке выполните:

```bash
ollama pull gemma3:1b
```

Для проверки установленных моделей:
```bash
ollama list
```

### 3. Запуск приложения

Рекомендуемый способ - использовать Live Server в VS Code:
1. Установите расширение Live Server
2. Откройте `index.html`
3. Нажмите "Go Live" в правом нижнем углу
4. Откроется браузер с приложением

## Использование

1. Введите вопрос в поле ввода
2. Нажмите кнопку отправки или Enter
3. Получите ответ от ИИ
4. История разговоров сохраняется автоматически

### Настройки

В панели настроек можно изменить:
- Температуру (0-2) - влияет на креативность ответов
- Максимальную длину ответа
- Выбрать модель ИИ

## Технические детали

Приложение использует JavaScript для взаимодействия с Ollama API. Основные компоненты:
- HTML интерфейс
- CSS стилизация
- JavaScript логика работы с API

Для работы требуется запущенный сервер Ollama на localhost:11434.
